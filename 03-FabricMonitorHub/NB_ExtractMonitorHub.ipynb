{
    "cells": [{
            "cell_type": "markdown",
            "source": ["# Fabric Monitor Hub Extraction\n", "This notebook calls the internal Microsoft Fabric APIs to extract the monitor hub to a lakehouse table."],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "605bc66d-8e73-4c58-aeac-415526e097ce"
        }, {
            "cell_type": "markdown",
            "source": ["## Setup"],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "e568acb7-dd75-4b94-8eb3-c7a7fa4dd151"
        }, {
            "cell_type": "code",
            "source": ["# Parameter and variables\n", "table_schema='logging'\n", "table_name='fabric_monitoring_hub'\n", "drop_existing = False\n", "extract_limit = 50"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 3,
                            "statement_ids": [3],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3268474Z",
                            "session_start_time": "2025-05-05T22:39:51.3278803Z",
                            "execution_start_time": "2025-05-05T22:40:03.5266896Z",
                            "execution_finish_time": "2025-05-05T22:40:04.0468099Z",
                            "parent_msg_id": "6e2e813e-ebf2-4eb8-b03b-e6473389981b"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 3, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 1,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "00a1b07a-5151-4148-9761-b077f982e07b"
        }, {
            "cell_type": "code",
            "source": ["# Imports\n", "import requests\n", "from datetime import datetime, timezone\n", "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType\n", "from pyspark.sql.functions import to_timestamp, unix_timestamp, col, when, expr,udf"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 4,
                            "statement_ids": [4],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3316699Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:04.0488185Z",
                            "execution_finish_time": "2025-05-05T22:40:04.4256927Z",
                            "parent_msg_id": "3733dceb-ced7-4924-903b-ef1e4eee5839"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 4, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 2,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "7422da6c-7591-442e-b367-a6fdeba6dc9e"
        }, {
            "cell_type": "code",
            "source": ["#If drop_existing is true then drop the table\n", "if drop_existing:\n", "    spark.sql(f\"DROP TABLE IF EXISTS {table_schema}.{table_name}\")"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 5,
                            "statement_ids": [5],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3339489Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:04.4277109Z",
                            "execution_finish_time": "2025-05-05T22:40:04.7439307Z",
                            "parent_msg_id": "677eb359-0efa-4b2c-8b74-2ec4c73db89a"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 5, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 3,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "f5a7048f-d286-4f65-8442-9fb466aaff63"
        }, {
            "cell_type": "code",
            "source": ["# Get Fabric token\n", "token = mssparkutils.credentials.getToken(\"https://api.fabric.microsoft.com/\")\n", "\n", "utc_now = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n", "delta_table_path = f\"Tables/{table_schema}/{table_name}\" "],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 6,
                            "statement_ids": [6],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3363304Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:04.7461305Z",
                            "execution_finish_time": "2025-05-05T22:40:08.1732246Z",
                            "parent_msg_id": "e01b154d-607f-45ae-8bce-a6c6ed2b86af"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 6, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 4,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "30e91522-7e96-47b4-95fa-8823b3c79744"
        }, {
            "cell_type": "markdown",
            "source": ["## Get Fabric Cluster\n", "Note API is unofficial"],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "57d31b3c-749b-416a-98f0-311784e998b6"
        }, {
            "cell_type": "code",
            "source": ["def get_cluster(token: str) -> dict:\n", "    headers = {\n", "        'Authorization': f'Bearer {token}',\n", "        'Accept': 'application/json'\n", "    }\n", "\n", "    url = \"https://api.powerbi.com/powerbi/globalservice/v201606/clusterdetails\"\n", "\n", "\n", "    try:\n", "        response = requests.get(url, headers=headers,  timeout=10)\n", "        print(f\"Status Code: {response.status_code}\")\n", "\n", "        if response.status_code == 200:\n", "            data = response.json()\n", "            return data.get(\"clusterUrl\")  # Only return clusterUrl\n", "        else:\n", "            print(f\"Request failed with status {response.status_code}: {response.text}\")\n", "            return None\n", "    except requests.exceptions.RequestException as e:\n", "        print(f\"Request error: {e}\")\n", "        return None\n", "\n", "\n", "cluster = get_cluster(token)\n", "\n", "# Exit notebook if cluster is null\n", "if cluster is None:\n", "    raise RuntimeError(\"Failed to retrieve Power BI cluster URL. Aborting notebook.\")\n"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 7,
                            "statement_ids": [7],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3385753Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:08.1752966Z",
                            "execution_finish_time": "2025-05-05T22:40:09.0246967Z",
                            "parent_msg_id": "0ffe0df1-3ce8-4f0d-b918-5891d2e7cac5"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 7, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }, {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": ["Status Code: 200\n"]
                }
            ],
            "execution_count": 5,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "1d7d43d7-5f4b-4698-a186-746a7c2d4488"
        }, {
            "cell_type": "markdown",
            "source": ["## Extract data from monitoring API\n", "Note API is unofficial"],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "3dd3b6a8-9ccd-46d8-aa15-ffa53c679718"
        }, {
            "cell_type": "code",
            "source": ["\n", "def fetch_monitoring_history(cluster_url, token: str, end_time, limit) -> dict:\n", "    headers = {\n", "        'Authorization': f'Bearer {token}',\n", "        'Accept': 'application/json'\n", "    }\n", "\n", "    url = f\"{cluster_url}/metadata/monitoringhub/histories\"\n", "\n", "    params = {\n", "        'limit': limit,\n", "        'endTime': end_time,\n", "        'startTime': '1970-01-01T00:00:00.000Z'\n", "    }\n", "\n", "    try:\n", "        response = requests.get(url, headers=headers, params=params, timeout=10)\n", "        print(f\"Status Code: {response.status_code}\")\n", "\n", "        if response.status_code == 200:\n", "            return response.json()\n", "        else:\n", "            print(f\"Request failed with status {response.status_code}: {response.text}\")\n", "            return {}\n", "    except requests.exceptions.RequestException as e:\n", "        print(f\"Request error: {e}\")\n", "        return {}\n", "\n", "\n", "history = fetch_monitoring_history(cluster, token, utc_now, extract_limit)"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 8,
                            "statement_ids": [8],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3407822Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:09.02659Z",
                            "execution_finish_time": "2025-05-05T22:40:09.8554078Z",
                            "parent_msg_id": "b11625d2-cfcc-4b17-b50d-f95c3b32fefb"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 8, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }, {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": ["Status Code: 200\n"]
                }
            ],
            "execution_count": 6,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "0eb90cda-b16a-40cc-ac8c-cf4d70f1283b"
        }, {
            "cell_type": "markdown",
            "source": ["## Convert API response to data frame\n", "Perform simple data transformations"],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "09121103-9fac-48dd-9f69-1c0d6e8251a0"
        }, {
            "cell_type": "code",
            "source": ["# Define a UDF to format duration\n", "def format_duration(seconds):\n", "    if seconds is None:\n", "        return None\n", "    seconds = int(seconds)\n", "    if seconds < 60:\n", "        return f\"{seconds}s\"\n", "    elif seconds < 3600:\n", "        minutes = seconds // 60\n", "        secs = seconds % 60\n", "        return f\"{minutes}m {secs}s\"\n", "    else:\n", "        hours = seconds // 3600\n", "        minutes = (seconds % 3600) // 60\n", "        secs = seconds % 60\n", "        return f\"{hours}h {minutes}m {secs}s\"\n", "        \n", "def format_status(statusString):\n", "    match statusString:\n", "        case \"Completed\":\n", "            return \"Succeeded\"\n", "        case \"InProgress\":\n", "            return \"In Progress\"\n", "        case \"NotStarted\":\n", "            return \"Not Started\"\n", "        case _:\n", "            return statusString\n", "\n", "def format_artifact_type(itemType):\n", "    match itemType:\n", "        case \"dataset\":\n", "            return \"Semantic Model\"\n", "        case \"Pipeline\":\n", "            return \"Data Pipeline\"\n", "        case \"SynapseNotebook\":\n", "            return \"Notebook\"\n", "        case _:\n", "            return itemType\n", "\n", "def create_df(data):\n", "    schema = StructType([\n", "        StructField(\"id\", LongType(), True),\n", "        StructField(\"artifactJobInstanceId\", StringType(), True),\n", "        StructField(\"artifactId\", LongType(), True),\n", "        StructField(\"artifactName\", StringType(), True),\n", "        StructField(\"artifactType\", StringType(), True),\n", "        StructField(\"jobScheduleTimeUtc\", StringType(), True),\n", "        StructField(\"jobStartTimeUtc\", StringType(), True),\n", "        StructField(\"jobEndTimeUtc\", StringType(), True),\n", "        StructField(\"statusString\", StringType(), True),\n", "        StructField(\"ownerUser\", StructType([\n", "            StructField(\"objectId\", StringType(), True),\n", "            StructField(\"userPrincipalName\", StringType(), True),\n", "            StructField(\"name\", StringType(), True)\n", "        ])),        \n", "        StructField(\"triggeredByArtifactName\", StringType(), True),\n", "        StructField(\"workspaceName\", StringType(), True),\n", "        StructField(\"isSuccessful\", BooleanType(), True),\n", "    ])\n", "    \n", "    df = spark.createDataFrame(data, schema=schema)\n", "    \n", "    # Convert strings to timestamps & Explode ownerUser\n", "    df= df.withColumn(\"jobScheduleTimeUtc\", to_timestamp(\"jobScheduleTimeUtc\")) \\\n", "        .withColumn(\"jobStartTimeUtc\", to_timestamp(\"jobStartTimeUtc\")) \\\n", "        .withColumn(\"jobEndTimeUtc\", to_timestamp(\"jobEndTimeUtc\")) \\\n", "        .withColumn(\"ownerObjectId\", col(\"ownerUser.objectId\")) \\\n", "        .withColumn(\"ownerName\", col(\"ownerUser.name\")) \\\n", "        .withColumn(\"ownerUserPrincipalName\", col(\"ownerUser.userPrincipalName\")) \\\n", "        .drop(\"ownerUser\")\n", "\n", "    # Calculate the duration\n", "    df = df.withColumn(\n", "        \"durationInSeconds\",\n", "        when(\n", "            col(\"jobEndTimeUtc\").isNotNull(),\n", "            (unix_timestamp(\"jobEndTimeUtc\") - unix_timestamp(\"jobStartTimeUtc\"))\n", "        ).otherwise(None)\n", "    )\n", "    \n", "    # Set up the formatting functions\n", "    format_duration_udf = udf(format_duration, StringType())\n", "    format_artifact_type_udf = udf(format_artifact_type, StringType())\n", "    format_status_udf = udf(format_status, StringType())\n", "\n", "    # add the formatted columns\n", "    df = df.withColumn(\"durationFormatted\", format_duration_udf(col(\"durationInSeconds\"))) \\\n", "        .withColumn(\"artifactTypeFormatted\", format_artifact_type_udf(col(\"artifactType\"))) \\\n", "        .withColumn(\"statusStringFormatted\", format_status_udf(col(\"statusString\")))\n", "\n", "    return df\n", "\n", "df = create_df(history)"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 9,
                            "statement_ids": [9],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3444211Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:09.8574581Z",
                            "execution_finish_time": "2025-05-05T22:40:11.4757554Z",
                            "parent_msg_id": "04a703b4-be29-4177-8ada-bc08eff6236f"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 9, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 7,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "121c31f6-e8f5-4c79-9733-a3fa8c8d926d"
        }, {
            "cell_type": "markdown",
            "source": ["## Save data frame to table"],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "ace2b8eb-e947-4304-9cbf-a9632c092df5"
        }, {
            "cell_type": "code",
            "source": ["from delta.tables import *\n", "if DeltaTable.isDeltaTable(spark, delta_table_path):\n", "    delta_table = DeltaTable.forPath(spark, delta_table_path)\n", "\n", "    (delta_table.alias(\"t\")\n", "    .merge(df.alias(\"s\"), 's.id = t.id')\n", "    .whenMatchedUpdateAll()\n", "    .whenNotMatchedInsertAll()\n", "    .execute()\n", "    )\n", "else: \n", "    df.write.mode(\"overwrite\").option(\"mergeSchema\",\"true\").format(\"delta\").save(delta_table_path)\n", "\n", "\n"],
            "outputs": [{
                    "output_type": "display_data",
                    "data": {
                        "application/vnd.livy.statement-meta+json": {
                            "spark_pool": null,
                            "statement_id": 10,
                            "statement_ids": [10],
                            "state": "finished",
                            "livy_statement_state": "available",
                            "session_id": "15549095-de79-4160-aa13-7790a0912e2d",
                            "normalized_state": "finished",
                            "queued_time": "2025-05-05T22:39:51.3465134Z",
                            "session_start_time": null,
                            "execution_start_time": "2025-05-05T22:40:11.4777421Z",
                            "execution_finish_time": "2025-05-05T22:40:23.3090993Z",
                            "parent_msg_id": "9996a4a8-ded3-4762-ac73-aa95d96c40a4"
                        },
                        "text/plain": "StatementMeta(, 15549095-de79-4160-aa13-7790a0912e2d, 10, Finished, Available, Finished)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 8,
            "metadata": {
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "id": "16f32b55-b70c-459c-92da-849d0e082ebb"
        }
    ],
    "metadata": {
        "kernel_info": {
            "name": "synapse_pyspark"
        },
        "kernelspec": {
            "name": "synapse_pyspark",
            "language": "Python",
            "display_name": "Synapse PySpark"
        },
        "language_info": {
            "name": "python"
        },
        "microsoft": {
            "language": "python",
            "language_group": "synapse_pyspark",
            "ms_spell_check": {
                "ms_spell_check_language": "en"
            }
        },
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        },
        "spark_compute": {
            "compute_id": "/trident/default",
            "session_options": {
                "conf": {
                    "spark.synapse.nbs.session.timeout": "1200000"
                }
            }
        },
        "dependencies": {
            "lakehouse": {
                "known_lakehouses": [{
                        "id": "31ecc3ee-4bab-4f50-b09a-2052d8c10567"
                    }
                ],
                "default_lakehouse": "31ecc3ee-4bab-4f50-b09a-2052d8c10567",
                "default_lakehouse_name": "LH_Silver_Lakehouse",
                "default_lakehouse_workspace_id": "e02a48ad-bde6-4907-9cdf-486e2f52602a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
